{
  "cells": [
    {
      "metadata": {
        "_uuid": "8fb4eba9118530498d757b09a9a33e7fe33c9266"
      },
      "cell_type": "markdown",
      "source": "# NYPD Complaint - Filling NaNs with Random Forest Regressor for Beginners\n### Data updated 7 June 2018\n\n### Notebook created - *2018-24-08*\n### Version - 1\n\n## **This kernel is continuation of previous one**\n\n### **List of kernels:**\n### 1. Previous, introductory notebook - [here](https://www.kaggle.com/mihalw28/nyc-crimes-2018-data-cleaning-part-i)\n### 2. This one - [here](https://www.kaggle.com/mihalw28/nyc-crimes-2018-random-forest-regressor-nans)"
    },
    {
      "metadata": {
        "_uuid": "4baeb805177b342efa33e0e7e766018683b65b29"
      },
      "cell_type": "markdown",
      "source": "## Introduction\n\nThis notebook is continuation of kernel [NYC Crimes 2018  - data cleaning, part I](https://www.kaggle.com/mihalw28/nyc-crimes-2018-data-cleaning-part-i). Like previous one, this kernel take up basic\ndata science skills like data cleaning and implementing regression to fill empty values. I found many inspirations and ideas for this notebook in *Hands-On Machine Learning with Scikit_Learn and TensorFlow*  book written by [Aurelion Geron](https://twitter.com/aureliengeron). Any comments about kernel errors and better solutions are welcome. "
    },
    {
      "metadata": {
        "_uuid": "d62b0edc4d405b18889683d2967c084a740965ef"
      },
      "cell_type": "markdown",
      "source": "## Activities I am planning to perform in this kernel\n\n\n### [FILL NAN VALUES IN PATROL_BORO COLUMN:](#1)\n1. [First things first](#2)\n2. [Import data & prepare for machine learning algorithms](#3)\n3. [Train models](#4)\n4. [Fine-tune](#5)\n5. [Evaluation and results](#6)\n"
    },
    {
      "metadata": {
        "_uuid": "6d0ef5ef33d4b7b7be0a9312a9a3ea69c311e4a0"
      },
      "cell_type": "markdown",
      "source": "<a id=\"1\"></a> <br>\n# Fill NaN values in PATROL_BORO column"
    },
    {
      "metadata": {
        "_uuid": "3b94720b4ebbf92a656e11b65a34bbddfa464fa7"
      },
      "cell_type": "markdown",
      "source": "<a id=\"2\"></a> <br>\n### First Things First"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Imports\n\n# Visualisations\nimport matplotlib.pyplot as plt \nimport matplotlib\n%matplotlib inline\n\n# Warnings\nimport warnings\nwarnings.filterwarnings(action = 'ignore')\n\n# Data exploration\nimport pandas as pd\n\n# Numerical\nimport numpy as np\n\n# Random\nnp.random.seed(11)\n\n# Files in dataset\nimport os\nprint(os.listdir(\"../input\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8d73c436d0bec4d26ae079523838431ffab986d4"
      },
      "cell_type": "markdown",
      "source": "<a id=\"3\"></a> <br>\n## Import data and prepare for machine learning algorithms"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Import data frame formed in part I of NYC crimes kernel\ncrimes = pd.read_csv(\"../input/crimes_df.csv\")\ncrimes.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8ac4f71ab20e3f5ec00ed703f1f13d0489301cea"
      },
      "cell_type": "code",
      "source": "# Find values with NaN in PATROL_BORO column, extract them and save as a new data frame.\nprint(\"Name of the PATROL BORO: \\n\", crimes['PATROL_BORO'].value_counts(dropna = False), sep = '')   # check if there any NaNs\npatrol_boro_nan = crimes[crimes['PATROL_BORO'].isnull()]   # df with PATROL_BORO NaNs only\npatrol_boro_nan = patrol_boro_nan.drop('PATROL_BORO', axis = 1)   # delete PATROL_BORO column",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ef58e1a0fa4fa2a544147e59e04b3806b8343330"
      },
      "cell_type": "code",
      "source": "# Create df without PATROL_BORO NaN values, to split in sets\ndf_p_b = crimes.dropna(subset = ['PATROL_BORO'], axis = 0).reset_index()   # reset_index() is crucial here\n# Sanity check\ndf_p_b['PATROL_BORO'].value_counts(dropna = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d62a4fa72ca597c331a09e55d91c8f625661b920"
      },
      "cell_type": "code",
      "source": "# Split data in train and test set. Use StratifiedShuffleSplit to make low (lower than splitting with purely random values)\nfrom sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 11)\nfor train_index, test_index in split.split(df_p_b, df_p_b['PATROL_BORO']):\n    strat_train_set = df_p_b.loc[train_index]\n    strat_test_set = df_p_b.loc[test_index]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "08226a8aa1544033c292421a57c2cc97e4114ea7"
      },
      "cell_type": "code",
      "source": "# Check values in test set\n#print(strat_test_set['PATROL_BORO'].value_counts(normalize = True))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fc53c27846aaf04471769b319ab1ce660d4f6dbf"
      },
      "cell_type": "code",
      "source": "# Create df with crimes/incidents labels of train set, and drop PATROL_BORO column (maybe not necessary to drop column, because I pick categorical columns manually)\ncrimes_labels = strat_train_set['PATROL_BORO'].copy().to_frame()\ncrimes = strat_train_set.drop('PATROL_BORO', axis = 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c1769912949c95c4c0a93fd384bd3dff80c23e20"
      },
      "cell_type": "code",
      "source": "# Quick plot for data check\ncrimes.plot(kind = 'scatter', x = 'Longitude', y = 'Latitude', marker = 'o', alpha = 0.08, figsize = (16,12));",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "22b9be260dc53448340aab73e84c7f237b2e0a22"
      },
      "cell_type": "code",
      "source": "# Select categories to feed the model, all numerical without index and one categoroical.\n# To be honest I didn`t wonder much time what to select from categorical series, but BORO_NM should be a perfect match\ncrimes_num = crimes.select_dtypes(include = [np.number]).drop('index', axis = 1)\ncrimes_cat = crimes['BORO_NM']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6ade56d892647b19e6cb41310e030ab312503f68"
      },
      "cell_type": "markdown",
      "source": "Application of SimpleImputer to fill NaNs in numerical values is a bit useless here, because there aren't any NaNs. Nevertheless, it is very usefull if the data set was not cleaned up before."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a103b3ec6079cc796a054e4c86d68886e20f96fd"
      },
      "cell_type": "code",
      "source": "# Deal with numerical NaNs \nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\")\nimputer.fit(crimes_num)\nimputer.transform(crimes_num)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e7911e48020b87527e4e7fecf604b6232c17f56a"
      },
      "cell_type": "code",
      "source": "# Encode crimes labels, use OneHotEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nonehot_encoder = OneHotEncoder(sparse = False)\ncrimes_labels_1hot = onehot_encoder.fit_transform(crimes_labels)\nprint(crimes_labels_1hot.shape)\ncrimes_labels_1hot",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "655d85cc3a9a84e8d58151b729a1e504eb12e28e"
      },
      "cell_type": "markdown",
      "source": "The next step is to write a custom transformer to automatically feed a pipeline with selected numerical or categorical attributes. Source [here](https://github.com/ageron/handson-ml/blob/master/02_end_to_end_machine_learning_project.ipynb)."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e01551b9fe7ac175ad1bf82d587c25fdbda9eab"
      },
      "cell_type": "code",
      "source": "# Write a selector \nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self, X, y = None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb5bbf64b3fefe44062a60aa5ec04533e59070c2"
      },
      "cell_type": "code",
      "source": "# Make pipelines for numerical and categorical attributes\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_attribs = list(crimes_num)\ncat_attribs = ['BORO_NM']\n\nnum_pipeline = Pipeline([\n    ('selector', DataFrameSelector(num_attribs)),\n    ('imputer', SimpleImputer(strategy=\"median\")),\n    ('std_scaler', StandardScaler()),\n])\n\ncat_pipeline = Pipeline([\n    ('selector', DataFrameSelector(cat_attribs)),\n    ('cat_encoder', OneHotEncoder(sparse=False)), \n])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0a3a3d614560dd341d9d6bd7f3e7131530b70a4e"
      },
      "cell_type": "code",
      "source": "# Create one pipeline for the whole process\nfrom sklearn.pipeline import FeatureUnion\nfull_pipeline = FeatureUnion(transformer_list=[\n    ('num_pipeline', num_pipeline),\n    ('cat_pipeline', cat_pipeline),\n])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "121e8d3f6ac7c502b4e38ad5da828d88110742af"
      },
      "cell_type": "code",
      "source": "# Encode values using full_pipeline\ncrimes_prepared = full_pipeline.fit_transform(crimes)\nprint(crimes_prepared.shape)\ncrimes_prepared",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68dcb1ceceb6cfaa1b3d72b1f9620019571787d7"
      },
      "cell_type": "markdown",
      "source": "<a id=\"4\"></a> <br>\n## Train models"
    },
    {
      "metadata": {
        "_uuid": "30fbf62c52bd52e5864491e6595d8ecefbbea3df"
      },
      "cell_type": "markdown",
      "source": "Time to select and train machine learning model."
    },
    {
      "metadata": {
        "_uuid": "74e5cf98b5c1b49d2cf0aadf3ab06da6ccba26cf"
      },
      "cell_type": "markdown",
      "source": "### **Linear Regression**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ff304d94b836dc369f48c6bb5b40207fa59c62c1"
      },
      "cell_type": "code",
      "source": "# Linear regression model\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(crimes_prepared, crimes_labels_1hot) #return to crimes_labels_encoded",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "30ca333eeb40354e2069fc4ad8ade50d99e83314"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_squared_error\ncrimes_predictions = lin_reg.predict(crimes_prepared)\nlin_mse = mean_squared_error(crimes_labels_1hot, crimes_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e7d8a315681b3eeed800f1065f8380fdd5a024d"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_absolute_error\n\nlin_mae = mean_absolute_error(crimes_labels_1hot, crimes_predictions)\nlin_mae",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "86b9a180612d5b09a04e2e280989e87a96aaa421"
      },
      "cell_type": "markdown",
      "source": "### **Decision Tree**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6c29168a51bbe9729e8bf4555b6f76ed42b7ed9b"
      },
      "cell_type": "code",
      "source": "# Decsision tree regressor model\nfrom sklearn.tree import DecisionTreeRegressor\ntree_reg = DecisionTreeRegressor(random_state=11)\ntree_reg.fit(crimes_prepared, crimes_labels_1hot)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e6756b14fd2a72d59f4cc6b1be1db0e7aff5ae9d"
      },
      "cell_type": "code",
      "source": "# Don't use code from this cell to predict labels. Data overfitted - too good to be true.\n# Uncomment below to check rsme.\n\n# crimes_predictions = tree_reg.predict(crimes_prepared)\n# tree_mse = mean_squared_error(crimes_labels_1hot, crimes_predictions)\n# tree_rmse = np.sqrt(tree_mse)\n# print(\"Decision Tree Regressor: rmse:\", tree_rmse) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4cb6c79c1985c4846caeea3ae2cb4b9043fa3a13"
      },
      "cell_type": "code",
      "source": "# Better option, cross validation\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(tree_reg, crimes_prepared, crimes_labels_1hot, scoring = 'neg_mean_squared_error', cv = 10)\ntree_rmse_scores = np.sqrt(-scores)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3dc9e3502a5769b1dfbab2bb314c4da77905dba7"
      },
      "cell_type": "code",
      "source": "# Display all scores\ndef display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "758e82a28b78d3ba2068f55340d4c79b45be46dd"
      },
      "cell_type": "code",
      "source": "# Execute display_scores(scores) function\ndisplay_scores(tree_rmse_scores)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7bcf0826ea6544bb0f5a4b53af1aeb696a7f1710"
      },
      "cell_type": "code",
      "source": "# Compute the same scores for Linear Regression\nlin_scores = cross_val_score(lin_reg, crimes_prepared, crimes_labels_1hot, scoring = 'neg_mean_squared_error', cv = 10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1967a1c8409dfc14989ae6c349fcc54df6fbd9f4"
      },
      "cell_type": "markdown",
      "source": "### **Random forest**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "22b99913ab60b422672bc99f6324c69a18969585"
      },
      "cell_type": "code",
      "source": "# Random forset Regressor model\nfrom sklearn.ensemble import RandomForestRegressor\nforest_reg = RandomForestRegressor(random_state=11)\nforest_reg.fit(crimes_prepared, crimes_labels_1hot)\n\ncrimes_predictions = forest_reg.predict(crimes_prepared)\nforest_mse = mean_squared_error(crimes_labels_1hot, crimes_predictions)\nforest_rmse = np.sqrt(forest_mse)\nprint(\"Random Forest Regressor -> rmse:\", forest_rmse)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "56bc8dd67aab01f8f952c219be1e3b2f47657777"
      },
      "cell_type": "code",
      "source": "# Compute cross_val_score for Random Forest Regressor\nfrom sklearn.model_selection import cross_val_score\nforest_scores = cross_val_score(forest_reg, crimes_prepared, crimes_labels_1hot, scoring='neg_mean_squared_error', cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8cf2ff5ae647dd9da473d7aa8c6b31d0b4a8784c"
      },
      "cell_type": "markdown",
      "source": "<a id=\"5\"></a> <br>\n## **Fine-tune model**"
    },
    {
      "metadata": {
        "_uuid": "bf473b5cc232cbcc80c58b1cd192475d4d11b087"
      },
      "cell_type": "markdown",
      "source": "### **Grid search**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "59f93a83a50a368961494d321e84d616e19d76cb"
      },
      "cell_type": "code",
      "source": "# Grid search using RFR\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = [\n    {'n_estimators': [3, 10, 30], 'max_features': [3, 4, 5, 6]},\n    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n]\nforest_reg = RandomForestRegressor(random_state = 11)\ngrid_search = GridSearchCV(forest_reg, param_grid, cv = 5, scoring = 'neg_mean_squared_error', \n                          return_train_score = True)\ngrid_search.fit(crimes_prepared, crimes_labels_1hot)\nprint(\"Grid search best parameters: \", grid_search.best_params_)\nprint(\"Grid search best estimator: \", grid_search.best_estimator_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ef145c57a98e7d20aa35b3d471e4b9b869da2f61"
      },
      "cell_type": "code",
      "source": "# Evaluation scores\nprint(\"Evaluation scores\")\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n    print(np.sqrt(-mean_score), params)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "781a9b2bcecd0f017018edd3b8c70dfb9ffeaf6e"
      },
      "cell_type": "markdown",
      "source": "### **Randomized search**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7eb4c4b73724bbcbbdb9abde55119521b05547b1"
      },
      "cell_type": "code",
      "source": "# Randomized search on RFR\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\nparam_distribs = {\n    'n_estimators': randint(low = 1, high = 200),\n    'max_features': randint(low = 1, high = 8),\n}\n\nforest_reg = RandomForestRegressor(random_state = 11)\nrnd_search = RandomizedSearchCV(forest_reg, param_distributions = param_distribs,\n                               n_iter = 10, cv = 5, scoring = 'neg_mean_squared_error', random_state = 11)\nrnd_search.fit(crimes_prepared, crimes_labels_1hot)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "973d07af373fba7fe3b70a2b372f1ed521a2d1dc"
      },
      "cell_type": "code",
      "source": "feature_importances = grid_search.best_estimator_.feature_importances_\nfeature_importances",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7e304f3b163ace882f9faa72999da690dd0f33ab"
      },
      "cell_type": "code",
      "source": "# Check most important attributes\ncat_encoder = cat_pipeline.named_steps['cat_encoder']\ncat_one_hot_attribs = list(cat_encoder.categories_[0])\nattributes = num_attribs + cat_one_hot_attribs\nsorted(zip(feature_importances, attributes), reverse = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bda7a6a7b11648a115f970b450f593939a312216"
      },
      "cell_type": "markdown",
      "source": "<a id=\"6\"></a> <br>\n## **Evaluation and results**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c346c4573cebc1ec8b0427f4a12a51a5a6c47883"
      },
      "cell_type": "code",
      "source": "# Evaluate model on test set\nfinal_model = grid_search.best_estimator_\n\nX_test = strat_test_set.drop('PATROL_BORO', axis = 1)\ny_test = strat_test_set['PATROL_BORO'].copy().to_frame()\n\n# Second step - OneHotEncoder, enoding integers to sparse matrix as an output, if (sparse = False) array as an output\nfrom sklearn.preprocessing import OneHotEncoder\ncat_encoder = OneHotEncoder(sparse = False)\ny_test_encoded_oh = cat_encoder.fit_transform(y_test)\ny_test_encoded_oh\n\nX_test_prepared = full_pipeline.transform(X_test)\nfinal_predictions = final_model.predict(X_test_prepared)\nfinal_predictions\nfinal_mse = mean_squared_error(y_test_encoded_oh, final_predictions)\nfinal_rmse = np.sqrt(final_mse)\nprint(\"Final score:\", final_rmse)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "604554cdfc892e9a8471e4cd988bf1ce8d827df5"
      },
      "cell_type": "code",
      "source": "# Find PATROL_BORO NaN values. Evaluate final model on patrol_boro_nan data frame\nX_to_find = full_pipeline.transform(patrol_boro_nan)\nNaNs_found = final_model.predict(X_to_find)\nNaNs_found[:5]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ad58baa13f109fb145d37d7ca30ff6273ef39d5"
      },
      "cell_type": "code",
      "source": "# Decode values\n# decode one hot oncoder\none_hot_decode = cat_encoder.inverse_transform(NaNs_found)\none_hot_decode[:5]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "92032acab4cbc1cc7f7dfa3f43380e9282d4b457"
      },
      "cell_type": "code",
      "source": "# Make data frame of founded NaNs and fix index\nfound = pd.DataFrame(one_hot_decode, columns = ['PATROL_BORO'], index = patrol_boro_nan.index)\nfound[:5]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8edd1c2639827170fb43ab1b9c58db17a64e8bbe"
      },
      "cell_type": "code",
      "source": "# Read original data frame\ncrimes_original = pd.read_csv(\"../input/crimes_df.csv\")\ncrimes_original['PATROL_BORO'].value_counts(dropna = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9713ef1ffda1683d233f344983eb5a1c96a7b9c"
      },
      "cell_type": "code",
      "source": "# Fill crimes_original PATROL_BORO NaNs with found values\nfor index in crimes_original['PATROL_BORO'], found['PATROL_BORO']:\n    crimes_original['PATROL_BORO'].loc[crimes_original['PATROL_BORO'].isnull()] = found['PATROL_BORO']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "22bbe8a4f1e6f58bc08797530d1d8a4e08f84f16"
      },
      "cell_type": "code",
      "source": "# Check\ncrimes_original.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dae49184b1b0f7a7901c66b86cbf5fc9cc651982"
      },
      "cell_type": "code",
      "source": "# Write df to csv\ncrimes_original.to_csv('crimes_NYC.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0bb5c2e29f93254e69399be55c1b72313389eecb"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}